{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_TextGeneration_01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f3677c9ea5e439da27097d67d63b56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce44bea909d64f369b16aaa316aec339",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cdcc2fcab11442048d9007ec6bd6b00c",
              "IPY_MODEL_22999ac595b1438cb59140cb0b4313b9"
            ]
          }
        },
        "ce44bea909d64f369b16aaa316aec339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdcc2fcab11442048d9007ec6bd6b00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d217742d7c74ffc870d93fb4be40ce7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f208fb654db5409e9450d0003c24f7fd"
          }
        },
        "22999ac595b1438cb59140cb0b4313b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a16b663ce2c4405a9a5a59d7d4f79f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 878kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f2f12455f7b442799dff0215aefd3fc"
          }
        },
        "1d217742d7c74ffc870d93fb4be40ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f208fb654db5409e9450d0003c24f7fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a16b663ce2c4405a9a5a59d7d4f79f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f2f12455f7b442799dff0215aefd3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5bd785aaa724a55ba612fd9d0355768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_91b4f5a56e194a13ba355185cad5d8ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f59e367530534a6eacdb6060a92e2964",
              "IPY_MODEL_4128fc0b03044efdac222f2f3028da1f"
            ]
          }
        },
        "91b4f5a56e194a13ba355185cad5d8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f59e367530534a6eacdb6060a92e2964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69f318d41f014c9a880e670cfe314574",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2096b252e594c439fdf16ae5595c46d"
          }
        },
        "4128fc0b03044efdac222f2f3028da1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_109aead79dbd4799b033b9c493843dc2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.21MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b07caa292d44732821917b08efd66c3"
          }
        },
        "69f318d41f014c9a880e670cfe314574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2096b252e594c439fdf16ae5595c46d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "109aead79dbd4799b033b9c493843dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b07caa292d44732821917b08efd66c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdc835c8656a4983821d71dc62e74794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3da1c39a1ca0485ca62144c9ee8aa103",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_207b6b6919644b2ab02ba37f737ec6de",
              "IPY_MODEL_9e7942b31215402d8f184ab06aadce3a"
            ]
          }
        },
        "3da1c39a1ca0485ca62144c9ee8aa103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "207b6b6919644b2ab02ba37f737ec6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3cf41582b55a457b8606fa154277b7dc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 764,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 764,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c2347044a9f4fc99b07290d07b32f1c"
          }
        },
        "9e7942b31215402d8f184ab06aadce3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b96833c206742e798daad54bbe0a0fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 764/764 [00:00&lt;00:00, 1.10kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f63ce89b9a3544c0bf62f777b40b5ce2"
          }
        },
        "3cf41582b55a457b8606fa154277b7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c2347044a9f4fc99b07290d07b32f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b96833c206742e798daad54bbe0a0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f63ce89b9a3544c0bf62f777b40b5ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43e55daf038b41ab924db49315d1ecec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_04a5faec38c04d85909ac72d791aabfd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cb55b14a1d946a39a84127e04f29e7e",
              "IPY_MODEL_5c350117f771479ca14fc8d792210396"
            ]
          }
        },
        "04a5faec38c04d85909ac72d791aabfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cb55b14a1d946a39a84127e04f29e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_357b66e2f56e4bc0849f4f5478b0f5e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3096618024,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3096618024,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d280748b9df449519277909fc83bbe27"
          }
        },
        "5c350117f771479ca14fc8d792210396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c7f201615d2a4ee5a5ad1551892c0660",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.10G/3.10G [01:32&lt;00:00, 33.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60675f8a5d804b8d8aa10d9ccb90d125"
          }
        },
        "357b66e2f56e4bc0849f4f5478b0f5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d280748b9df449519277909fc83bbe27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7f201615d2a4ee5a5ad1551892c0660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60675f8a5d804b8d8aa10d9ccb90d125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLW8pN-XSwHp"
      },
      "source": [
        "Experimenting Text Generation with Transformers using HuggingFace. Also exploring different decoding methods like Beam Search, Top-K sampling and Top-P sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk8_cVhn40k7",
        "outputId": "8f902077-20f7-4f19-d1a9-9242dac08d56"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 55.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=cfd26b9ee3bbd3863f76dfc378cadb37f57ac0f0badbbc27a0560e2c58d10708\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ssLkTR3S2KW"
      },
      "source": [
        "SEED = 34 #Reproducability\r\n",
        "MAX_LEN = 70 #Maximum number of words in the output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310,
          "referenced_widgets": [
            "7f3677c9ea5e439da27097d67d63b56f",
            "ce44bea909d64f369b16aaa316aec339",
            "cdcc2fcab11442048d9007ec6bd6b00c",
            "22999ac595b1438cb59140cb0b4313b9",
            "1d217742d7c74ffc870d93fb4be40ce7",
            "f208fb654db5409e9450d0003c24f7fd",
            "7a16b663ce2c4405a9a5a59d7d4f79f4",
            "3f2f12455f7b442799dff0215aefd3fc",
            "c5bd785aaa724a55ba612fd9d0355768",
            "91b4f5a56e194a13ba355185cad5d8ac",
            "f59e367530534a6eacdb6060a92e2964",
            "4128fc0b03044efdac222f2f3028da1f",
            "69f318d41f014c9a880e670cfe314574",
            "a2096b252e594c439fdf16ae5595c46d",
            "109aead79dbd4799b033b9c493843dc2",
            "2b07caa292d44732821917b08efd66c3",
            "cdc835c8656a4983821d71dc62e74794",
            "3da1c39a1ca0485ca62144c9ee8aa103",
            "207b6b6919644b2ab02ba37f737ec6de",
            "9e7942b31215402d8f184ab06aadce3a",
            "3cf41582b55a457b8606fa154277b7dc",
            "5c2347044a9f4fc99b07290d07b32f1c",
            "2b96833c206742e798daad54bbe0a0fc",
            "f63ce89b9a3544c0bf62f777b40b5ce2",
            "43e55daf038b41ab924db49315d1ecec",
            "04a5faec38c04d85909ac72d791aabfd",
            "9cb55b14a1d946a39a84127e04f29e7e",
            "5c350117f771479ca14fc8d792210396",
            "357b66e2f56e4bc0849f4f5478b0f5e5",
            "d280748b9df449519277909fc83bbe27",
            "c7f201615d2a4ee5a5ad1551892c0660",
            "60675f8a5d804b8d8aa10d9ccb90d125"
          ]
        },
        "id": "tPI0xntGT0Df",
        "outputId": "eca29d04-1120-4a2f-8e79-bd353c777750"
      },
      "source": [
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer #Retrieve Transformers\r\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\") #Extract GPT2 Large Tokenizer\r\n",
        "GPT2 = TFGPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id) #Extract GPT2 Large model"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f3677c9ea5e439da27097d67d63b56f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5bd785aaa724a55ba612fd9d0355768",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdc835c8656a4983821d71dc62e74794",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=764.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43e55daf038b41ab924db49315d1ecec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3096618024.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2-large.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZgDROXCUIpp",
        "outputId": "e35ef07c-95c0-49ce-c804-50e985ae546c"
      },
      "source": [
        "GPT2.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tfgp_t2lm_head_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "transformer (TFGPT2MainLayer multiple                  774030080 \n",
            "=================================================================\n",
            "Total params: 774,030,080\n",
            "Trainable params: 774,030,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QeQ0uPUViY8"
      },
      "source": [
        "Decoding Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tDO27I2VmFb"
      },
      "source": [
        "1. First Pass (Greedy Search):\r\n",
        "\r\n",
        "The word with the highest probability is predicted as the next word using the below equation\r\n",
        "\r\n",
        ">$w_{t} = argmax_{w}P(w|w_{1:t-1})$\r\n",
        "\r\n",
        "at each timestep $t$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ3AvauzVZCJ"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s67APr1CXgAY"
      },
      "source": [
        "input_sequence = \"This is a simple sequence, based on\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx77SmHrXprW"
      },
      "source": [
        "input_ids = tokenizer.encode(input_sequence, return_tensors='tf') #Encoding the input sequence"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WEjowoLX1Oa"
      },
      "source": [
        "greedy_output = GPT2.generate(input_ids, max_length = MAX_LEN) #Text generated based on the Greedy Search"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keO3UuxKYQzE",
        "outputId": "10d6e437-48cc-4c8c-85f5-3dabd13c09cb"
      },
      "source": [
        "print('Output: \\n')\r\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output: \n",
            "\n",
            "This is a simple sequence, based on the idea that the first two steps are the most important.\n",
            "\n",
            "The first step is to find the first element in the sequence. This is done by using the first element of the sequence as a key.\n",
            "\n",
            "The second step is to find the second element in the sequence. This is done by using\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft2kCZ5CYpgr"
      },
      "source": [
        "2. Beam Search:\r\n",
        "\r\n",
        "Since the Greedy Search always gives priority to the word with the highest probability, it masks the words with the lowest probability. This is resolved by Beam Search\r\n",
        "\r\n",
        "When using Beam Search the model tracks and keeps the $num_beams$ of hypotheses at each time step,  so the model is able to compare the alternative paths as its generate text. $n\\_gram$ penalty can be included by setting $no\\_repeat\\_ngram\\_size = 2$ which ensures that no 2 grams appear twice. The $num\\_return\\_sequences = 5$ is set, inorde to see what the other 5 beams looked like.\r\n",
        "\r\n",
        "The parameters has to be set in Generate function to use the Beam Seach "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAq3M3z0YaOK"
      },
      "source": [
        "beam_outputs = GPT2.generate(\r\n",
        "    input_ids, \r\n",
        "    max_length = MAX_LEN, \r\n",
        "    num_beams = 5, \r\n",
        "    no_repeat_ngram_size = 2, \r\n",
        "    num_return_sequences = 5, \r\n",
        "    early_stopping = True\r\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSqZARJkiPZg"
      },
      "source": [
        "print(\"Output:\\n\" + 100 * '-')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-QdXBHxib2-",
        "outputId": "45cc15fd-55c9-45f5-8f2d-23cf27d6fd1f"
      },
      "source": [
        "for i, beam_output in enumerate(beam_outputs):\r\n",
        "      print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: This is a simple sequence, based on the fact that the first letter of each word is the same as the last letter in the previous word.\n",
            "\n",
            "For example, if you want to say \"I love you\", you would write \"i-love-you\" and then write the rest of the words in reverse order. If you wanted to\n",
            "1: This is a simple sequence, based on the fact that the first letter of each word is the same as the last letter in the previous word.\n",
            "\n",
            "For example, if you want to say \"I love you\", you would write \"i-love-you\" and then write the rest of the words in this sequence: \"love\", \"\n",
            "2: This is a simple sequence, based on the fact that the first letter of each word is the same as the last letter in the previous word.\n",
            "\n",
            "For example, if you want to say \"I love you\", you would write \"i-love-you\" and then write the rest of the words in reverse order. This is called a\n",
            "3: This is a simple sequence, based on the fact that the first letter of each word is the same as the last letter in the previous word.\n",
            "\n",
            "For example, if you want to say \"I love you\", you would write \"i-love-you\" and then write the rest of the words in reverse order. If you were to\n",
            "4: This is a simple sequence, based on the fact that the first letter of each word is the same as the last letter in the previous word.\n",
            "\n",
            "For example, if you want to say \"I love you\", you would write \"i-love-you\" and then write the rest of the words in reverse order. This is called \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIqWEAwhjAWr"
      },
      "source": [
        "From the above outputs it is noticed that, 5 different beam hypothesis are all same. The variation can be seen by increasing the $num\\_beams$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99Ng-tFnmvp6"
      },
      "source": [
        "3. Basic Sampling:\r\n",
        "\r\n",
        "Instead Predicting the next word based on the highest probability, the next word can be randomly picked based on the Conditional Probability distribution.\r\n",
        "\r\n",
        "$w_{t} =  P(w|w_{1:t-1})$\r\n",
        "\r\n",
        "The $temperature$ parameter increases the chances of highest probability words and decreases the chances of low probability words in the sampling.\r\n",
        "\r\n",
        "$do\\_sample = True$ is set to implement sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXqlQXupichx"
      },
      "source": [
        "sample_output = GPT2.generate(\r\n",
        "                             input_ids, \r\n",
        "                             do_sample = True, \r\n",
        "                             max_length = MAX_LEN, \r\n",
        "                             top_k = 0, \r\n",
        "                             temperature = 0.8)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96i59CBgpYgr",
        "outputId": "7983a100-02b2-4be5-f080-9496967d6e2a"
      },
      "source": [
        "print('Output : \\n')\r\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output : \n",
            "\n",
            "This is a simple sequence, based on the following Python code:\n",
            "\n",
            "import random height = random.randint(1, 6) # height of the image, in pixels # randomization is done each frame, based on the image size. # The average number of bits per pixel is given by the inverse of the X-coordinate.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YukUUYnite35"
      },
      "source": [
        "4. Top-K Sampling:\r\n",
        "\r\n",
        "The Top-K most likely words are selected and the entire probability mass is shifted to these $K$ words. In this case, it avoids the phenonmenon of increasing the chances of highest probability words and decreasing the chances of highest probability words. Instead it just removes low probability words all together.\r\n",
        "\r\n",
        "Top-K is set - in need of many of the top words to consider our conditional probability distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyagOc8Nqb0Q"
      },
      "source": [
        "sample_output = GPT2.generate(input_ids, do_sample = True, max_length = MAX_LEN, top_k = 50)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcj3rODsvKyT",
        "outputId": "d0800ace-80d4-47d6-cc05-77c58d7eb6ea"
      },
      "source": [
        "print(\"Output:\\n\")\r\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens = True), '...')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "\n",
            "This is a simple sequence, based on a random sample and it doesn't require much in the way of memory allocation and doesn't make heavy use of random number generation. As an extreme example, it might allocate a vector or integer array of length 1,000,000 and a random object of width 100. With the \"random\" parameter, you ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oax9QnAv7Iq"
      },
      "source": [
        "5. Top-P Sampling:\r\n",
        "\r\n",
        "Instead of choosing the Top-K most likely words, we choose the smallest set of words with the total probability more than $p$, and then the entire proability mass is shifted to the words in this set.\r\n",
        "\r\n",
        "The major difference between the Top-K and Top-P is, the Top-K value will be static and the number of words chosen will be always same. But in case of Top-P sampling, the size of the set can change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnMtw4TfvUhO"
      },
      "source": [
        "sample_output = GPT2.generate(input_ids, do_sample = True, max_length = MAX_LEN, top_p = 0.8, top_k = 0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2yi5sJS10lN",
        "outputId": "899df3e0-a8d9-48f4-e48a-420b722e2a62"
      },
      "source": [
        "print('Output:\\n')\r\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens = True), '...')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "\n",
            "This is a simple sequence, based on a static search:\n",
            "\n",
            "for(i=0; i< 16; i++) {\n",
            "\n",
            "We replace the eight bytes with a MZ bytes, and then if the result is not an NNN byte, use an explicit or getGzdMZ() to compute the remainder. If the ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09-kvW6V2rzo"
      },
      "source": [
        "6. Check the Diversity of the generated sentences by setting, `top-k`, `top-p` and `temperature`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HT9hCWr3A0z"
      },
      "source": [
        "sample_outputs = GPT2.generate(input_ids, do_sample = True, max_length = 2*MAX_LEN, temperature = .7, \r\n",
        "                               top_k = 50, top_p = 0.85, num_return_sequences = 5)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPAge_Sp3KZA",
        "outputId": "67dbf55a-665c-4ada-c390-d02c8af01eaf"
      },
      "source": [
        "print('Output:\\n')\r\n",
        "for i, sample_output in enumerate(sample_outputs):\r\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(sample_output, skip_special_tokens = True)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "\n",
            "0: This is a simple sequence, based on a set of equations that can be solved for a given set of inputs.\n",
            "\n",
            "If the input is a positive number, the output is a number from 1 to 9. If the input is a negative number, the output is a number from 0 to 9.\n",
            "\n",
            "The solution is a list of numbers from 1 to 9.\n",
            "\n",
            "The function calculates the sum of the numbers in the list.\n",
            "\n",
            "The function returns the number in the list.\n",
            "\n",
            "If the input is a positive number, the output is a number from 1 to 9. If the input is a negative number, the output is a number from 0 to 9.\n",
            "\n",
            "...\n",
            "1: This is a simple sequence, based on the simple rule of the first line.\n",
            "\n",
            "The first line is the line where the program starts.\n",
            "\n",
            "The second line is the line where the program stops.\n",
            "\n",
            "The third line is the line where the program continues.\n",
            "\n",
            "The fourth line is the line where the program ends.\n",
            "\n",
            "This is the basic sequence for a program.\n",
            "\n",
            "The basic sequence for a program is the same as the first line.\n",
            "\n",
            "The first line is the line where the program starts.\n",
            "\n",
            "The second line is the line where the program stops.\n",
            "\n",
            "The third line is the line where the program continues.\n",
            "\n",
            "The fourth line is...\n",
            "2: This is a simple sequence, based on a simple model.\n",
            "\n",
            "The first step is to have the player choose a weapon, and then to be able to use that weapon in a variety of ways.\n",
            "\n",
            "The player can shoot and use melee weapons, or he can throw his melee weapon and use it as a shield, or he can use it to knock out enemies.\n",
            "\n",
            "The player can also use the shield as a weapon, if he is in a situation where he doesn't have a weapon.\n",
            "\n",
            "The player can also use the shield as a weapon, if he is in a situation where he doesn't have a weapon. The player can also use the shield as a weapon...\n",
            "3: This is a simple sequence, based on the standard \"Hobbit\" pattern. It is the first part of a sequence of the same size, and the last part of a sequence of the same size.\n",
            "\n",
            "Hobbit_Sequence ( int n, int s )\n",
            "\n",
            "Hobbit_Sequence(int n, int s)\n",
            "\n",
            "Hobbit_Sequence(int n, int s)\n",
            "\n",
            "Hobbit_Sequence(int n, int s)\n",
            "\n",
            "Hobbit_Sequence(int n, int s)\n",
            "\n",
            "Hobbit_Sequence(int n, int s)\n",
            "\n",
            "Hobbit_Sequence...\n",
            "4: This is a simple sequence, based on a simple rule:\n",
            "\n",
            "A single element is not an element of the same type as another element.\n",
            "\n",
            "A single element is not a subelement of another element.\n",
            "\n",
            "A single element is not a child of another element.\n",
            "\n",
            "A single element is not a child of another element and is not a descendant of another element.\n",
            "\n",
            "A single element is not a child of another element and is not a descendant of another element.\n",
            "\n",
            "A single element is not a child of another element and is not a descendant of another element.\n",
            "\n",
            "A single element is not a descendant of another element and is not a descendant of another element....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9jKcP8d3PJN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}